{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario \n",
    "You are a data analyst for a retail company. Your task is to analyze customer and sales data \n",
    "to generate meaningful insights while handling real-world data issues. \n",
    " \n",
    "### **Task 1** \n",
    "Load the given datasets into Pandas DataFrames. Inspect the datasets and perform the \n",
    "following: \n",
    "- Display the first few rows of each dataset. \n",
    "- Show the total number of rows and columns. \n",
    "- Check for missing values in each dataset and handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Dataset:\n",
      "   CustomerID  Age         City\n",
      "0           1   22     New York\n",
      "1           2   23  Los Angeles\n",
      "2           3   24      Chicago\n",
      "3           4   25      Houston\n",
      "4           5   26      Phoenix\n",
      "Shape: (100, 3)\n",
      "Missing values:\n",
      " CustomerID    0\n",
      "Age           0\n",
      "City          0\n",
      "dtype: int64\n",
      "\n",
      "Sales Dataset:\n",
      "   SaleID  CustomerID     Product  Amount\n",
      "0     101           1      Laptop     200\n",
      "1     102           2  Smartphone     500\n",
      "2     103           3      Tablet     800\n",
      "3     104           4  Headphones    1100\n",
      "4     105           5     Monitor    1400\n",
      "Shape: (400, 4)\n",
      "Missing values:\n",
      " SaleID        0\n",
      "CustomerID    0\n",
      "Product       0\n",
      "Amount        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "customers = pd.read_csv(\"customers.csv\")  \n",
    "sales = pd.read_csv(\"sales.csv\") \n",
    "\n",
    "print(\"Customers Dataset:\")\n",
    "print(customers.head())\n",
    "print(\"Shape:\", customers.shape)\n",
    "print(\"Missing values:\\n\", customers.isnull().sum())\n",
    "\n",
    "print(\"\\nSales Dataset:\")\n",
    "print(sales.head())\n",
    "print(\"Shape:\", sales.shape)\n",
    "print(\"Missing values:\\n\", sales.isnull().sum())\n",
    "\n",
    "customers = customers.dropna()\n",
    "sales = sales.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 2** \n",
    "Using the customers.csv file, convert its data into a Python dictionary. Use the dictionary to \n",
    "filter customers from a specific city. Repeat the operation using a DataFrame and compare \n",
    "the efficiency of both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "customers_dict = customers.to_dict(orient=\"records\")\n",
    "\n",
    "specific_city = \"New York\"  \n",
    "filtered_customers_dict = [customer for customer in customers_dict if customer[\"City\"] == specific_city]\n",
    "print(\"Filtered Customers using Dictionary:\", filtered_customers_dict)\n",
    "\n",
    "\n",
    "filtered_customers_df = customers[customers[\"City\"] == specific_city]\n",
    "print(\"Filtered Customers using DataFrame:\\n\", filtered_customers_df)\n",
    "\n",
    "start = time.time()\n",
    "[customer for customer in customers_dict if customer[\"City\"] == specific_city]\n",
    "dict_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "customers[customers[\"City\"] == specific_city]\n",
    "df_time = time.time() - start\n",
    "\n",
    "print(f\"Dictionary Filter Time: {dict_time}, DataFrame Filter Time: {df_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 3**\n",
    "Identify duplicate rows, if any, in the datasets. Remove these duplicates to ensure clean data. \n",
    "After cleaning, verify that there are no duplicates left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in Customers: 0\n",
      "Duplicate rows in Sales: 0\n",
      "After cleaning, duplicates in Customers: 0\n",
      "After cleaning, duplicates in Sales: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Duplicate rows in Customers:\", customers.duplicated().sum())\n",
    "print(\"Duplicate rows in Sales:\", sales.duplicated().sum())\n",
    "\n",
    "customers = customers.drop_duplicates()\n",
    "sales = sales.drop_duplicates()\n",
    "\n",
    "print(\"After cleaning, duplicates in Customers:\", customers.duplicated().sum())\n",
    "print(\"After cleaning, duplicates in Sales:\", sales.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 4** \n",
    "Create a new column in the sales.csv data that reflects the total amount after applying a \n",
    "10% discount on the Amount column. Group the data by Product and calculate the total sales \n",
    "for each product. Present the results in a well-structured format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sales by Product:\n",
      " Product\n",
      "Headphones     79200.0\n",
      "Laptop         14400.0\n",
      "Monitor       100800.0\n",
      "Smartphone     36000.0\n",
      "Tablet         57600.0\n",
      "Name: Discounted_Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sales[\"Discounted_Amount\"] = sales[\"Amount\"] * 0.9\n",
    "\n",
    "total_sales_by_product = sales.groupby(\"Product\")[\"Discounted_Amount\"].sum()\n",
    "print(\"Total Sales by Product:\\n\", total_sales_by_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 5** \n",
    "Filter the data in the customers.csv file to retain only those customers whose age falls in the \n",
    "range of 25 to 35. Save the filtered data in a new structure and analyze how many customers \n",
    "belong to each city within this age range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers by City (Age 25-35):\n",
      " City\n",
      "Houston        11\n",
      "Phoenix         8\n",
      "New York        7\n",
      "Los Angeles     7\n",
      "Chicago         7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_customers = customers[(customers[\"Age\"] >= 25) & (customers[\"Age\"] <= 35)]\n",
    "\n",
    "city_counts = filtered_customers[\"City\"].value_counts()\n",
    "print(\"Customers by City (Age 25-35):\\n\", city_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 6**\n",
    "Merge the customers.csv and sales.csv datasets on CustomerID. From the merged \n",
    "dataset: \n",
    "- Identify the city that generated the highest total sales. \n",
    "- Find the product with the most units sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City with Highest Sales: Phoenix\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Quantity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m city_with_highest_sales \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity with Highest Sales:\u001b[39m\u001b[38;5;124m\"\u001b[39m, city_with_highest_sales)\n\u001b[1;32m----> 6\u001b[0m product_with_most_units \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProduct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuantity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct with Most Units Sold:\u001b[39m\u001b[38;5;124m\"\u001b[39m, product_with_most_units)\n",
      "File \u001b[1;32mc:\\Users\\Sky Solutions\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1950\u001b[0m     )\n\u001b[1;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sky Solutions\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: Quantity'"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_data = pd.merge(customers, sales, on=\"CustomerID\")\n",
    "\n",
    "city_with_highest_sales = merged_data.groupby(\"City\")[\"Amount\"].sum().idxmax()\n",
    "print(\"City with Highest Sales:\", city_with_highest_sales)\n",
    "\n",
    "product_with_most_units = merged_data.groupby(\"Product\")[\"Quantity\"].sum().idxmax()\n",
    "print(\"Product with Most Units Sold:\", product_with_most_units)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 7** \n",
    "Explore the merged dataset to derive insights: \n",
    "• Display the unique values in the City and Product columns. \n",
    "• Calculate the mean and median of the Amount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Cities: ['New York' 'Los Angeles' 'Chicago' 'Houston' 'Phoenix']\n",
      "Unique Products: ['Laptop' 'Smartphone' 'Tablet' 'Headphones' 'Monitor']\n",
      "Mean of Amount: 800.0\n",
      "Median of Amount: 800.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_cities = merged_data[\"City\"].unique()\n",
    "unique_products = merged_data[\"Product\"].unique()\n",
    "print(\"Unique Cities:\", unique_cities)\n",
    "print(\"Unique Products:\", unique_products)\n",
    "\n",
    "mean_amount = merged_data[\"Amount\"].mean()\n",
    "median_amount = merged_data[\"Amount\"].median()\n",
    "print(\"Mean of Amount:\", mean_amount)\n",
    "print(\"Median of Amount:\", median_amount)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
